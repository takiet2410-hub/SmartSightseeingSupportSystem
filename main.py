from fastapi import FastAPI, HTTPException, Depends
from schemas import RecommendationRequest, RecommendationResponse
from modules.vectorizer import HybridVectorizer
from modules.retrieval import retrieve_context
from modules.generation import build_rag_prompt, call_llm_api, parse_llm_response
from core.config import settings
from contextlib import asynccontextmanager
import unicodedata
import os

# Kh·ªüi t·∫°o vectorizer to√†n c·ª•c
vectorizer = HybridVectorizer()

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("--- STARTUP: Loading models ---")
    try:
        # Ki·ªÉm tra xem file vectorizer c√≥ t·ªìn t·∫°i kh√¥ng
        if os.path.exists(settings.VECTORIZER_PATH):
            vectorizer.load_fitted_tfidf(settings.VECTORIZER_PATH)
            print("Models loaded successfully.")
        else:
            print(f"Kh√¥ng t√¨m th·∫•y file vectorizer t·∫°i: {settings.VECTORIZER_PATH}")
            print("üëâ B·∫°n c·∫ßn ch·∫°y l·ªánh 'python ingest_data.py' ƒë·ªÉ t·∫°o file n√†y tr∆∞·ªõc.")
            
    except Exception as e:
        print(f"‚ùå CRITICAL ERROR during startup: {e}")
    
    
    yield
    print("--- SHUTDOWN ---")
    
app = FastAPI(
    title="Smart Tourism System - 'Before' Module",
    lifespan=lifespan
)

# 2. H√ÄM CHU·∫®N H√ìA INPUT (LOGIC Y H·ªÜT B√äN INGEST)
def standardize_input(text: str) -> str:
    if not text:
        return None # Tr·∫£ v·ªÅ None ƒë·ªÉ filter b·ªè qua n·∫øu user kh√¥ng nh·∫≠p
    text = str(text)
    text = unicodedata.normalize('NFC', text)
    text = text.replace('\u2013', '-').replace('\u2014', '-')
    return text.strip().lower()

@app.get("/")
def read_root():
    return {"message": "Welcome to the Smart Tourism 'Before' Module API"}

@app.post("/recommendations", response_model=RecommendationResponse)
async def get_recommendations(request: RecommendationRequest):
    try:
        # 1. Chu·∫©n h√≥a input (nh∆∞ ƒë√£ s·ª≠a ·ªü b∆∞·ªõc tr∆∞·ªõc)
        if request.hard_constraints:
            req = request.hard_constraints
            req.available_time = standardize_input(req.available_time)
            req.budget_range = standardize_input(req.budget_range)
            req.companion_tag = standardize_input(req.companion_tag)
            req.season_tag = standardize_input(req.season_tag)
        
        print(f"Received query: {request.vibe_prompt}")
        
        # 2. Vector Search & Retrieval
        query_vector = vectorizer.transform_single(request.vibe_prompt)
        retrieved_context = retrieve_context(request.hard_constraints, query_vector)
        
        if not retrieved_context:
            return RecommendationResponse(
                status="error", 
                recommendations=[], 
                debug_info={"message": "No destinations found matching criteria."}
            )

        # 3. T·∫°o Dictionary ƒë·ªÉ tra c·ª©u nhanh (Name -> Full Data)
        # M·ª•c ƒë√≠ch: L·∫•y l·∫°i ƒë·ªãa ch·ªâ, rating ch√≠nh x√°c t·ª´ DB m√† kh√¥ng c·∫ßn LLM sinh ra
        context_map = {doc['name']: doc for doc in retrieved_context}

        # 4. G·ªçi LLM ƒë·ªÉ ch·ªçn v√† vi·∫øt l·ªùi b√¨nh
        context_str = "\n\n".join([str(doc) for doc in retrieved_context])
        prompt = build_rag_prompt(context=context_str, user_query=request.vibe_prompt)
        llm_raw_response = call_llm_api(prompt)
        parsed_response = parse_llm_response(llm_raw_response)
        
        if "error" in parsed_response:
             raise HTTPException(status_code=500, detail=parsed_response["error"])

        # 5. === B∆Ø·ªöC QUAN TR·ªåNG: GH√âP D·ªÆ LI·ªÜU (DATA ENRICHMENT) ===
        llm_recs = parsed_response.get("recommendations", [])
        final_recommendations = []

        for rec in llm_recs:
            # T√¨m l·∫°i doc g·ªëc trong context d·ª±a v√†o t√™n
            original_doc = context_map.get(rec.get("name"))
            
            if original_doc:
                # N·∫øu t√¨m th·∫•y, copy th√¥ng tin c·ª©ng t·ª´ DB sang
                rec["location_province"] = original_doc.get("location_province", "Unknown")
                rec["specific_address"] = original_doc.get("specific_address", "Unknown")
                rec["overall_rating"] = original_doc.get("overall_rating", 0.0)
                rec["image_urls"] = original_doc.get("image_urls", [])
            else:
                # Fallback: N·∫øu LLM b·ªãa t√™n ho·∫∑c s·ª≠a t√™n l√†m kh√¥ng t√¨m th·∫•y trong map
                # G√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh ƒë·ªÉ tr√°nh l·ªói 500
                rec["location_province"] = ""
                rec["specific_address"] = ""
                rec["overall_rating"] = 0.0
                rec["image_urls"] = []
            
            final_recommendations.append(rec)

        # 6. Tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë√£ ƒë·∫ßy ƒë·ªß field
        return RecommendationResponse(
            status="success",
            recommendations=final_recommendations,
            debug_info={
                "retrieved_count": len(retrieved_context), 
                # L·∫•y score c·ªßa th·∫±ng ƒë·∫ßu ti√™n t√¨m th·∫•y (n·∫øu c√≥)
                "top_match_score": retrieved_context[0].get('score') if retrieved_context else 0
            }
        )

    except Exception as e:
        print(f"An error occurred: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    
if __name__ == "__main__":
    import uvicorn
    print("Run the server using: uvicorn main:app --reload")