import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from sentence_transformers import SentenceTransformer
from joblib import dump, load

# ===============================
# 1Ô∏è‚É£ Load d·ªØ li·ªáu
# ===============================
def load_data(path="vietnam_provinces.csv"):
    df = pd.read_csv(path)
    df["description"] = df["description_vi"] + " " + df["description_en"]
    return df


# ===============================
# 2Ô∏è‚É£ X√¢y d·ª±ng m√¥ h√¨nh Hybrid
# ===============================
def build_hybrid_model(df, alpha=0.6, beta=0.4):
    print("üîπ ƒêang kh·ªüi t·∫°o m√¥ h√¨nh TF-IDF...")
    vectorizer = TfidfVectorizer(stop_words="english", max_df=0.8, ngram_range=(1, 2))
    tfidf_matrix = vectorizer.fit_transform(df["description"]).toarray()

    print("üîπ ƒêang t·∫£i SentenceTransformer (multilingual)...")
    model = SentenceTransformer("intfloat/multilingual-e5-base")
    embed_matrix = model.encode(df["description"], normalize_embeddings=True)

    # Chu·∫©n h√≥a TF-IDF
    tfidf_norm = tfidf_matrix / np.linalg.norm(tfidf_matrix, axis=1, keepdims=True)

    # Gh√©p vector
    hybrid_features = np.hstack([
        alpha * tfidf_norm,
        beta * embed_matrix
    ])

    # Hu·∫•n luy·ªán KNN
    print("üîπ ƒêang hu·∫•n luy·ªán KNN...")
    knn = NearestNeighbors(n_neighbors=5, metric="cosine")
    knn.fit(hybrid_features)

    print("‚úÖ Hu·∫•n luy·ªán xong Hybrid-KNN.")
    return vectorizer, model, knn, hybrid_features


# ===============================
# 3Ô∏è‚É£ G·ª£i √Ω ƒëi·ªÉm ƒë·∫øn
# ===============================
def recommend_destinations(query, df, vectorizer, model, knn, alpha=0.6, beta=0.4, top_k=5):
    # Encode query
    q_tfidf = vectorizer.transform([query]).toarray()
    q_embed = model.encode([query], normalize_embeddings=True)

    # Chu·∫©n h√≥a & k·∫øt h·ª£p
    q_hybrid = np.hstack([
        alpha * q_tfidf / np.linalg.norm(q_tfidf, axis=1, keepdims=True),
        beta * q_embed
    ])

    # Truy v·∫•n KNN
    distances, indices = knn.kneighbors(q_hybrid)

    print(f"\nüîç K·∫øt qu·∫£ g·ª£i √Ω cho: '{query}'\n")
    for i, idx in enumerate(indices[0]):
        score = 1 - distances[0][i]
        print(f"{i+1}. {df.iloc[idx]['province']} (score={score:.3f}) ‚Äì {df.iloc[idx]['description_vi']}")


# ===============================
# 4Ô∏è‚É£ L∆∞u / t·∫£i m√¥ h√¨nh (tu·ª≥ ch·ªçn)
# ===============================
def save_model(vectorizer, model, knn):
    dump(vectorizer, "tfidf_vectorizer.pkl")
    dump(knn, "knn_hybrid.pkl")
    model.save("sentence_transformer/")
    print("üíæ ƒê√£ l∆∞u m√¥ h√¨nh TF-IDF, KNN, SentenceTransformer.")


def load_model():
    vectorizer = load("tfidf_vectorizer.pkl")
    knn = load("knn_hybrid.pkl")
    model = SentenceTransformer("sentence_transformer/")
    print("üì¶ ƒê√£ t·∫£i l·∫°i m√¥ h√¨nh.")
    return vectorizer, model, knn


# ===============================
# 5Ô∏è‚É£ Ch·∫°y th·ª≠ (Demo)
# ===============================
if __name__ == "__main__":
    # 1. Load d·ªØ li·ªáu
    df = load_data("vietnam_provinces.csv")

    # 2. Build model
    vectorizer, model, knn, hybrid_features = build_hybrid_model(df)

    # 3. Input
    test_queries = [
        "T√¥i mu·ªën ng·∫Øm sao tr√™n tr·ªùi",
        "T√¥i th√≠ch kh√°m ph√° thi√™n nhi√™n v√† kh√≠ h·∫≠u m√°t m·∫ª",
        "T√¥i mu·ªën tr·∫£i nghi·ªám vƒÉn h√≥a truy·ªÅn th·ªëng v√† di s·∫£n",
        "T√¥i mu·ªën n∆°i s√¥i ƒë·ªông, c√≥ nhi·ªÅu m√≥n ƒÉn ngon v√† cu·ªôc s·ªëng v·ªÅ ƒë√™m"
    ]

    for query in test_queries:
        recommend_destinations(query, df, vectorizer, model, knn)
