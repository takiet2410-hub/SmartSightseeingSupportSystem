# ğŸ§­ Vibe Recommendation Pipeline â€“ Smart Tourism System (Context 2)

## 1ï¸âƒ£ Má»¥c tiÃªu

Pipeline nÃ y xá»­ lÃ½ **Ã½ Ä‘á»‹nh trá»«u tÆ°á»£ng (vibe)** cá»§a ngÆ°á»i dÃ¹ng â€“ vÃ­ dá»¥:

> â€œtÃ´i muá»‘n Ä‘i nÆ¡i yÃªn bÃ¬nh, nhiá»u cÃ¢y xanh, khÃ­ háº­u mÃ¡t máº»â€

Má»¥c tiÃªu lÃ  **tÃ¬m cÃ¡c Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch cÃ³ cáº£m xÃºc tÆ°Æ¡ng Ä‘á»“ng nháº¥t** trong cÆ¡ sá»Ÿ dá»¯ liá»‡u (CSDL) thÃ´ng qua mÃ´ hÃ¬nh **SentenceTransformer + TF-IDF + Cosine Similarity + KNN**.

---

## 2ï¸âƒ£ Tá»•ng quan pipeline

NgÆ°á»i dÃ¹ng nháº­p vibe
â†“
Vector hÃ³a (TF-IDF + SentenceTransformer)
â†“
TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (Cosine Similarity)
â†“
TÃ¬m top Ä‘á»‹a Ä‘iá»ƒm gáº§n nháº¥t (KNN / Ranking)
â†“
Tráº£ vá» gá»£i Ã½ Ä‘á»‹a Ä‘iá»ƒm phÃ¹ há»£p


---

## 3ï¸âƒ£ CÃ¡c thÃ nh pháº§n chi tiáº¿t

### ğŸ”¹ 3.1 TF-IDF (Term Frequency - Inverse Document Frequency)

TF-IDF Ä‘Ã¡nh giÃ¡ táº§m quan trá»ng cá»§a má»™t tá»« trong táº­p vÄƒn báº£n.

\[
\text{TF-IDF}(t,d) = TF(t,d) \times \log\left(\frac{N}{DF(t)}\right)
\]

- \(TF(t,d)\): táº§n suáº¥t cá»§a tá»« \(t\) trong tÃ i liá»‡u \(d\)  
- \(DF(t)\): sá»‘ tÃ i liá»‡u chá»©a tá»« \(t\)  
- \(N\): tá»•ng sá»‘ tÃ i liá»‡u  

TF-IDF giÃºp mÃ´ hÃ¬nh náº¯m Ä‘Æ°á»£c **tá»« khÃ³a Ä‘áº·c trÆ°ng** cá»§a tá»«ng Ä‘á»‹a Ä‘iá»ƒm.

---

### ğŸ”¹ 3.2 SentenceTransformer (Semantic Embedding)

#### ğŸ§  Tá»•ng quan

**SentenceTransformer** lÃ  má»™t mÃ´ hÃ¬nh há»c sÃ¢u dá»±a trÃªn **BERT (Bidirectional Encoder Representations from Transformers)**, Ä‘Æ°á»£c tinh chá»‰nh Ä‘á»ƒ táº¡o ra vector biá»ƒu diá»…n (embedding) cho toÃ n bá»™ cÃ¢u hoáº·c Ä‘oáº¡n vÄƒn â€” thay vÃ¬ tá»«ng tá»« riÃªng láº».

Má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh lÃ  Ã¡nh xáº¡ cÃ¡c cÃ¢u cÃ³ **nghÄ©a tÆ°Æ¡ng tá»±** vÃ o **nhá»¯ng Ä‘iá»ƒm gáº§n nhau trong khÃ´ng gian vector**.

#### ğŸ”¬ Cáº¥u trÃºc tá»•ng quÃ¡t
Chuá»—i Ä‘áº§u vÃ o (sentence)
â†“
Tokenizer (chuyá»ƒn tá»« â†’ token ID)
â†“
Transformer Encoder (BERT / MiniLM / DistilBERT)
â†“
Pooling Layer (Mean / Max / CLS token)
â†“
Sentence Embedding (vector ngá»¯ nghÄ©a)

Má»—i cÃ¢u sau khi Ä‘i qua mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng má»™t vector cÃ³ 384â€“768 chiá»u (tuá»³ model), vÃ­ dá»¥ `all-MiniLM-L6-v2` táº¡o vector 384 chiá»u.

#### âš™ï¸ CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng chi tiáº¿t

1. **Tokenizer**  
Chuyá»ƒn cÃ¢u Ä‘áº§u vÃ o thÃ nh chuá»—i token ID, vÃ­ dá»¥: 
"ÄÃ  Láº¡t yÃªn bÃ¬nh" â†’ [101, 3912, 1652, 102]
(mÃ£ hÃ³a dá»±a trÃªn WordPiece Tokenization)

2. **Transformer Encoder**  
Ãp dá»¥ng *multi-head self-attention*, cho phÃ©p mÃ´ hÃ¬nh náº¯m báº¯t quan há»‡ giá»¯a cÃ¡c tá»« theo ngá»¯ cáº£nh hai chiá»u:
\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V
\]
Trong Ä‘Ã³:
- \(Q, K, V\): ma tráº­n truy váº¥n, khÃ³a, giÃ¡ trá»‹  
- \(d_k\): kÃ­ch thÆ°á»›c khÃ´ng gian áº©n (hidden size)

3. **Pooling Layer**  
Trung bÃ¬nh hÃ³a (mean pooling) toÃ n bá»™ token embedding thÃ nh má»™t vector duy nháº¥t:
\[
s = \frac{1}{n}\sum_{i=1}^{n}h_i
\]
vá»›i \(h_i\) lÃ  embedding cá»§a token thá»© *i*.

4. **Sentence Embedding**  
Káº¿t quáº£ lÃ  vector ngá»¯ nghÄ©a biá»ƒu diá»…n toÃ n cÃ¢u, vÃ­ dá»¥:
[0.123, -0.041, 0.332, ... , 0.027]

#### ğŸ§© Trong bÃ i toÃ¡n Vibe Recommendation

Trong há»‡ thá»‘ng du lá»‹ch thÃ´ng minh, SentenceTransformer giÃºp:
- Hiá»ƒu **ngá»¯ nghÄ©a sÃ¢u** cá»§a mÃ´ táº£ Ä‘á»‹a Ä‘iá»ƒm (â€œthÃ nh phá»‘ má» sÆ°Æ¡ngâ€ â‰ˆ â€œthá»i tiáº¿t mÃ¡t láº¡nh, sÆ°Æ¡ng phá»§â€).
- Hiá»ƒu **vibe trá»«u tÆ°á»£ng** tá»« ngÆ°á»i dÃ¹ng (â€œchá»¯a lÃ nhâ€, â€œyÃªn bÃ¬nhâ€, â€œchillâ€).
- Káº¿t ná»‘i cÃ¡c cÃ¡ch diá»…n Ä‘áº¡t khÃ¡c nhau cÃ³ cÃ¹ng ná»™i dung cáº£m xÃºc.

VÃ­ dá»¥:

| Vibe ngÆ°á»i dÃ¹ng | Vibe Ä‘á»‹a Ä‘iá»ƒm | Cosine Similarity |
|------------------|---------------|------------------|
| â€œyÃªn tÄ©nh, khÃ­ háº­u mÃ¡t máº»â€ | â€œkhÃ´ng khÃ­ trong lÃ nh, nhiá»u cÃ¢y thÃ´ngâ€ | 0.89 |
| â€œnÃ¡o nhiá»‡t, sÃ´i Ä‘á»™ngâ€ | â€œbiá»ƒn, tiá»‡c, lá»… há»™iâ€ | 0.86 |
| â€œchá»¯a lÃ nhâ€ | â€œspa, thiÃªn nhiÃªn, tÄ©nh tÃ¢mâ€ | 0.81 |

CÃ¡c vector embedding Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  dÃ¹ng Ä‘á»ƒ tÃ­nh **cosine similarity**, giÃºp há»‡ thá»‘ng gá»£i Ã½ Ä‘Æ°á»£c cÃ¡c Ä‘iá»ƒm du lá»‹ch phÃ¹ há»£p vá» *tÃ¢m tráº¡ng* chá»© khÃ´ng chá»‰ dá»±a vÃ o *tá»« khÃ³a*.

#### ğŸ’¡ MÃ´ hÃ¬nh sá»­ dá»¥ng

Trong pipeline hiá»‡n táº¡i:
```python
from sentence_transformers import SentenceTransformer
st = SentenceTransformer("all-MiniLM-L6-v2")

---

## 4ï¸âƒ£ Chuáº©n hÃ³a pipeline hybrid (TF-IDF + SentenceTransformer)

Ta káº¿t há»£p hai loáº¡i vector Ä‘á»ƒ táº­n dá»¥ng cáº£ **ngá»¯ nghÄ©a** vÃ  **tá»« khÃ³a**:

\[
V_{hybrid} = [V_{TFIDF} ; V_{ST}]
\]

(tá»©c lÃ  ná»‘i 2 vector theo chiá»u ngang)

---

## 5ï¸âƒ£ Cosine Similarity

Äá»™ Ä‘o tÆ°Æ¡ng Ä‘á»“ng giá»¯a hai vector:

\[
\text{cosine\_similarity}(A, B) = \frac{A \cdot B}{\|A\| \times \|B\|}
\]

GiÃ¡ trá»‹:
- 1 â†’ giá»‘ng há»‡t  
- 0 â†’ khÃ´ng liÃªn quan  
- -1 â†’ trÃ¡i ngÆ°á»£c  

---

## 6ï¸âƒ£ KNN (K-Nearest Neighbors)

KNN tÃ¬m **k Ä‘iá»ƒm gáº§n nháº¥t** vá»›i vector Ä‘áº§u vÃ o trong khÃ´ng gian cosine.

\[
d_{cos}(A,B) = 1 - \text{cosine\_similarity}(A,B)
\]

â†’ Chá»n **k Ä‘á»‹a Ä‘iá»ƒm cÃ³ khoáº£ng cÃ¡ch nhá» nháº¥t** Ä‘á»ƒ gá»£i Ã½.

---

## 7ï¸âƒ£ Code triá»ƒn khai chuáº©n hÃ³a pipeline

### ğŸ”¸ Import thÆ° viá»‡n
```python
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import normalize
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors
from sentence_transformers import SentenceTransformer

df = pd.DataFrame({
    "name": ["ÄÃ  Láº¡t", "Nha Trang", "Há»™i An", "Sa Pa"],
    "description": [
        "yÃªn tÄ©nh, nhiá»u cÃ¢y thÃ´ng, khÃ­ háº­u mÃ¡t máº», chá»¯a lÃ nh",
        "biá»ƒn, nÄƒng Ä‘á»™ng, nÃ¡o nhiá»‡t, láº·n biá»ƒn, vui chÆ¡i",
        "cá»• kÃ­nh, yÃªn bÃ¬nh, di sáº£n, vÄƒn hÃ³a, truyá»n thá»‘ng",
        "nÃºi, láº¡nh, thiÃªn nhiÃªn, hÃ¹ng vÄ©, yÃªn bÃ¬nh"
    ]
})

1. TF-IDF Vectorization
tfidf = TfidfVectorizer(max_features=5000)
tfidf_vecs = tfidf.fit_transform(df["description"])
tfidf_vecs = normalize(tfidf_vecs)

2. SentenceTransformer Embedding
st = SentenceTransformer("all-MiniLM-L6-v2")
st_vecs = st.encode(df["description"].tolist(), convert_to_numpy=True)
st_vecs = normalize(st_vecs)

3. Táº¡o Hybrid Vector
hybrid_vecs = np.concatenate([tfidf_vecs.toarray(), st_vecs], axis=1)

4. Táº¡o KNN Model
knn = NearestNeighbors(metric="cosine", n_neighbors=3)
knn.fit(hybrid_vecs)

5. Vector hÃ³a input ngÆ°á»i dÃ¹ng
user_vibe = "tÃ´i muá»‘n Ä‘i nÆ¡i yÃªn bÃ¬nh, nhiá»u cÃ¢y xanh, khÃ­ háº­u mÃ¡t máº»"

user_tfidf = tfidf.transform([user_vibe]).toarray()
user_st = st.encode([user_vibe], convert_to_numpy=True)
user_vec = np.concatenate([user_tfidf, user_st], axis=1)
user_vec = normalize(user_vec)

6. TÃ­nh Cosine Similarity + KNN gá»£i Ã½
# Cosine Similarity
sim_scores = cosine_similarity(user_vec, hybrid_vecs).flatten()

# KNN
distances, indices = knn.kneighbors(user_vec)

# Hiá»ƒn thá»‹ káº¿t quáº£
for idx in indices[0]:
    print(f"ğŸ {df['name'][idx]} â€” similarity: {sim_scores[idx]:.3f}"

ğŸ’¡ Káº¿t quáº£ máº«u
ğŸ ÄÃ  Láº¡t â€” similarity: 0.893
ğŸ Sa Pa â€” similarity: 0.752
ğŸ Há»™i An â€” similarity: 0.640

## 8ï¸âƒ£ Tá»•ng há»£p cÃ´ng thá»©c pipeline

Äá»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a "vibe" cá»§a ngÆ°á»i dÃ¹ng vÃ  má»—i Ä‘á»‹a Ä‘iá»ƒm Ä‘Æ°á»£c tÃ­nh báº±ng **Cosine Similarity** giá»¯a hai vector hybrid (TF-IDF + SentenceTransformer):

\[
\text{Sim}(u, i) = \cos\left( [TFIDF(u); ST(u)], [TFIDF(i); ST(i)] \right)
\]

Trong Ä‘Ã³:
- **u**: vector vibe cá»§a ngÆ°á»i dÃ¹ng  
- **i**: vector Ä‘áº·c trÆ°ng cá»§a Ä‘á»‹a Ä‘iá»ƒm trong CSDL  
- **cos**: hÃ m cosine similarity  

Náº¿u sá»­ dá»¥ng KNN Ä‘á»ƒ láº¥y *k* Ä‘iá»ƒm gáº§n nháº¥t:

\[
\text{Top}_k = \text{argsort}_i(1 - \text{Sim}(u, i))[:k]
\]

---

## 9ï¸âƒ£ Æ¯u Ä‘iá»ƒm cá»§a mÃ´ hÃ¬nh hybrid

| PhÆ°Æ¡ng phÃ¡p | Æ¯u Ä‘iá»ƒm | Háº¡n cháº¿ |
|--------------|----------|----------|
| **TF-IDF** | Hiá»ƒu rÃµ tá»« khÃ³a cá»¥ thá»ƒ (vÃ­ dá»¥ â€œbiá»ƒnâ€, â€œnÃºiâ€) | KhÃ´ng hiá»ƒu ngá»¯ nghÄ©a |
| **SentenceTransformer** | Hiá»ƒu ngá»¯ cáº£nh, tá»« Ä‘á»“ng nghÄ©a, diá»…n Ä‘áº¡t tá»± nhiÃªn | Tá»‘n bá»™ nhá»› hÆ¡n |
| **KNN** | Truy váº¥n nhanh top-k Ä‘iá»ƒm tÆ°Æ¡ng tá»± | KhÃ´ng há»c tham sá»‘ |
| **Cosine Similarity** | ÄÆ¡n giáº£n, hiá»‡u quáº£ trong khÃ´ng gian vector | KhÃ´ng mÃ´ hÃ¬nh hÃ³a phi tuyáº¿n |

---

## ğŸ”Ÿ á»¨ng dá»¥ng trong há»‡ thá»‘ng du lá»‹ch thÃ´ng minh

| MÃ´-Ä‘un | Vai trÃ² |
|--------|----------|
| **Context 1** | Thu tháº­p dá»¯ liá»‡u (Overpass API + Wikipedia) |
| **Context 2** | Xá»­ lÃ½ Vibe (TF-IDF + SentenceTransformer + KNN) |
| **Context 3** | Tá»•ng há»£p Ä‘iá»ƒm (thá»i tiáº¿t, khoáº£ng cÃ¡ch, rating, cáº£m xÃºc) |
| **Context 4** | Gá»£i Ã½ cuá»‘i cÃ¹ng cho ngÆ°á»i dÃ¹ng |
